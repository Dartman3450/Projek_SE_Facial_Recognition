# -*- coding: utf-8 -*-
"""YOLOV11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1gOiRliTIm9Je9J_IoZenvtDD-fqChggZ
"""

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d vishesh1412/celebrity-face-image-dataset

!unzip celebrity-face-image-dataset.zip -d ./celebrity_data

import os
import shutil
import random

dataset_path = './celebrity_data/Celebrity Faces Dataset' # Adjust this path if needed based on unzipping

# Get the list of celebrity names (which are the directory names)
celebrity_names = sorted(os.listdir(dataset_path))
num_classes = len(celebrity_names)
print(f"Found {num_classes} celebrities (classes).")
print("Celebrities:", celebrity_names)

# You can also count total images
total_images = 0
for celebrity in celebrity_names:
    celebrity_path = os.path.join(dataset_path, celebrity)
    if os.path.isdir(celebrity_path): # Ensure it's a directory
        num_images = len(os.listdir(celebrity_path))
        print(f"- {celebrity}: {num_images} images")
        total_images += num_images
print(f"\nTotal images in the dataset: {total_images}")

import os
import shutil
import random

# Customize this path to your dataset location
original_dataset_dir = './celebrity_data/Celebrity Faces Dataset'# ðŸ‘ˆ change this
base_dir = './data'  # Where weâ€™ll create train/val/test folders

# Split ratios
train_split = 0.7
val_split = 0.15
test_split = 0.15

# Reset folders if they already exist
if os.path.exists(base_dir):
    shutil.rmtree(base_dir)

for split in ['train', 'val', 'test']:
    os.makedirs(os.path.join(base_dir, split), exist_ok=True)

# Loop through class folders
for class_name in os.listdir(original_dataset_dir):
    class_path = os.path.join(original_dataset_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    # Create split folders for each class
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)

    # Shuffle and split images
    images = os.listdir(class_path)
    random.shuffle(images)

    train_end = int(len(images) * train_split)
    val_end = train_end + int(len(images) * val_split)

    train_images = images[:train_end]
    val_images = images[train_end:val_end]
    test_images = images[val_end:]

    # Move files to respective directories
    for img in train_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'train', class_name, img))
    for img in val_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'val', class_name, img))
    for img in test_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'test', class_name, img))

print("âœ… Dataset split into train, val, and test!")

!pip install ultralytics

from google.colab import files
files.upload()

from ultralytics import YOLO

# Load model
model = YOLO("yolo11m-cls.pt")

# Train model dengan pengaturan scheduler
train_results = model.train(
    data="data",
    epochs=30,
    batch=16,
    imgsz=512,
    lr0=0.0008,
    lrf=0.05,
    optimizer="adamW",
    momentum=0.85,
    weight_decay=0.002,
    patience=10,
    dropout=0.4,
    cos_lr=True,
    label_smoothing=0.2,
    close_mosaic=20,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    iou=0.5,
    cls=0.6,
    pretrained = True
)

!zip -r /content/train_faces_result.zip /content/runs/classify/train

from google.colab import files
files.download('/content/runs/classify/train')

from ultralytics import YOLO

# Load your trained model (best.pt or last.pt)
model = YOLO("/content/runs/classify/train/weights/best.pt")  # adjust path if needed
3

!mkdir /content/test_images
!find /content/data/test -name "*.jpg" | head -n 10 | xargs -I {} cp {} /content/test_images/

results = model.predict(source="/content/test_images", save=True)