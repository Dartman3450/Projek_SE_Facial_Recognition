# -*- coding: utf-8 -*-
"""MobileNetV2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VP-mFirjr-Fw2Ow_MGcAwbSVzyrbisR6
"""

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d vishesh1412/celebrity-face-image-dataset

!unzip celebrity-face-image-dataset.zip -d ./celebrity_data

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import MobileNetV2 # Or ResNet50, MobileNetV2, etc.
from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import os
import shutil # For organizing files if needed
from sklearn.model_selection import train_test_split # If you need to manually split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import cv2

dataset_path = './celebrity_data/Celebrity Faces Dataset' # Adjust this path if needed based on unzipping

# Get the list of celebrity names (which are the directory names)
celebrity_names = sorted(os.listdir(dataset_path))
num_classes = len(celebrity_names)
print(f"Found {num_classes} celebrities (classes).")
print("Celebrities:", celebrity_names)

# You can also count total images
total_images = 0
for celebrity in celebrity_names:
    celebrity_path = os.path.join(dataset_path, celebrity)
    if os.path.isdir(celebrity_path): # Ensure it's a directory
        num_images = len(os.listdir(celebrity_path))
        print(f"- {celebrity}: {num_images} images")
        total_images += num_images
print(f"\nTotal images in the dataset: {total_images}")

import os
import shutil
import random

# Customize this path to your dataset location
original_dataset_dir = './celebrity_data/Celebrity Faces Dataset'# ðŸ‘ˆ change this
base_dir = './data'  # Where weâ€™ll create train/val/test folders

# Split ratios
train_split = 0.7
val_split = 0.15
test_split = 0.15

# Reset folders if they already exist
if os.path.exists(base_dir):
    shutil.rmtree(base_dir)

for split in ['train', 'val', 'test']:
    os.makedirs(os.path.join(base_dir, split), exist_ok=True)

# Loop through class folders
for class_name in os.listdir(original_dataset_dir):
    class_path = os.path.join(original_dataset_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    # Create split folders for each class
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)

    # Shuffle and split images
    images = os.listdir(class_path)
    random.shuffle(images)

    train_end = int(len(images) * train_split)
    val_end = train_end + int(len(images) * val_split)

    train_images = images[:train_end]
    val_images = images[train_end:val_end]
    test_images = images[val_end:]

    # Move files to respective directories
    for img in train_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'train', class_name, img))
    for img in val_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'val', class_name, img))
    for img in test_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'test', class_name, img))

print("âœ… Dataset split into train, val, and test!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input # Changed for DenseNet

IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE = 32

# Data generator for training (with augmentation)
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input, # Use DenseNet's preprocess_input
    rotation_range=40,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    channel_shift_range=10.0,
    fill_mode='nearest'
)

# Data generator for validation and testing (only preprocessing, no augmentation)
val_test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input # Use DenseNet's preprocess_input
)

# Paths to the newly created split directories
train_data_dir = './data/train'
val_data_dir = './data/val'
test_data_dir = './data/test'


train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True,
    seed=42
)

validation_generator = val_test_datagen.flow_from_directory(
    val_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False, # No need to shuffle validation data
    seed=42
)

test_generator = val_test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False, # No need to shuffle test data
    seed=42
)

# Verify class indices
print("\nTrain Generator Class Indices:", train_generator.class_indices)
print("Validation Generator Class Indices:", validation_generator.class_indices)
print("Test Generator Class Indices:", test_generator.class_indices)

# Store class labels for later use (ensure it's from train_generator as it's used for training)
class_labels = list(train_generator.class_indices.keys())
num_classes = len(class_labels) # Update num_classes based on actual classes found
print(f"\nNumber of classes detected by train_generator: {num_classes}")

import tensorflow as tf
from tensorflow.keras.applications import MobileNetV2 # Changed to DenseNet121 #Restnet50

# Load the pretrained base model (DenseNet121)
base_model = MobileNetV2 (
    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3), # 3 for RGB channels
    include_top=False,                       # Excludes the final classification layer
    weights='imagenet'                       # Load weights pretrained on ImageNet
)

# Freeze the layers of the base model initially
base_model.trainable = False

# You can still print the summary if you wish
# base_model.summary()

from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.models import Model

# Get the output of the base model
x = base_model.output

# Add a global spatial average pooling layer
x = GlobalAveragePooling2D()(x)

# Add a fully-connected layer
x = Dense(1024, activation='relu')(x)

# Add a dropout layer for regularization
x = Dropout(0.5)(x)

# Add the final output layer with softmax activation
predictions = Dense(num_classes, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

early_stopping = EarlyStopping(
    monitor='val_loss',  # Metric to monitor (could also be 'val_accuracy')
    patience=10,         # Number of epochs with no improvement after which training will be stopped
                         # Increase if you think your model needs more time to converge,
                         # decrease if it overfits too quickly.
    verbose=1,           # To see messages when it triggers
    restore_best_weights=True # Restores model weights from the epoch with the best
                              # value of the monitored metric. This is VERY useful!
)

# ModelCheckpoint: Saves the model or weights at some interval.
# We'll save only the best model based on 'val_loss'.
model_checkpoint_path = 'best_face_recognition_model.keras' # Using .keras format
model_checkpoint = ModelCheckpoint(
    filepath=model_checkpoint_path,
    monitor='val_loss',    # Metric to monitor
    save_best_only=True,   # Only save the model if `val_loss` has improved
    verbose=1              # To see messages when the model is saved
)

model.compile(optimizer=Adam(learning_rate=0.001),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

EPOCHS = 50 # Start with a moderate number of epochs, e.g., 10-25
            # You can increase this later if the model is still improving.

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

model.save('celebrity_face_recognition_model.h5') # Saves the model in HDF5 format
# Or for TensorFlow SavedModel format:
# model.save('celebrity_face_recognition_model_tf')

# Evaluate the model
val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"\nValidation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy*100:.2f}%")

# Plot training & validation accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc)) # Use len(acc) to get the actual number of epochs run

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# --- Optional: Fine-tuning ---
# Unfreeze some layers of the base model
base_model.trainable = True

# Fine-tune from this layer onwards
fine_tune_at = 100 # Example: Unfreeze layers from the 100th layer onwards
                   # For MobileNetV2, a good starting point might be after a certain block.
                   # You'll need to inspect base_model.summary() to choose this.

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

# Re-compile the model with a lower learning rate for fine-tuning
model.compile(optimizer=Adam(learning_rate=0.0001), # Lower learning rate
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# model.summary() # Check which layers are trainable

# Continue training (fine-tuning)
FINE_TUNE_EPOCHS = 30 # Train for a few more epochs
TOTAL_EPOCHS = EPOCHS + FINE_TUNE_EPOCHS

history_fine_tune = model.fit(
    train_generator,
    epochs=TOTAL_EPOCHS,
    initial_epoch=history.epoch[-1] + 1, # Start from where the previous training stopped
    validation_data=validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

# Save the fine-tuned model
model.save('celebrity_face_recognition_model_fine_tuned.h5')

# Plot the fine-tuning results (append to previous history)
# acc += history_fine_tune.history['accuracy']
# val_acc += history_fine_tune.history['val_accuracy']
# loss += history_fine_tune.history['loss']
# val_loss += history_fine_tune.history['val_loss']

# epochs_range_fine_tune = range(TOTAL_EPOCHS)

#  plt.figure(figsize=(12, 4))
#  plt.subplot(1, 2, 1)
#  plt.plot(epochs_range_fine_tune, acc, label='Training Accuracy')
#  plt.plot(epochs_range_fine_tune, val_acc, label='Validation Accuracy')
#  plt.legend(loc='lower right')
#  plt.title('Training and Validation Accuracy (with Fine-Tuning)')

#  plt.subplot(1, 2, 2)
#  plt.plot(epochs_range_fine_tune, loss, label='Training Loss')
#  plt.plot(epochs_range_fine_tune, val_loss, label='Validation Loss')
#  plt.legend(loc='upper right')
#  plt.title('Training and Validation Loss (with Fine-Tuning)')
#  plt.show()

# --- Plot Fine-tuning Results ---
acc_fine = history_fine_tune.history['accuracy']
val_acc_fine = history_fine_tune.history['val_accuracy']
loss_fine = history_fine_tune.history['loss']
val_loss_fine = history_fine_tune.history['val_loss']

epochs_range_fine = range(len(acc_fine)) # Use the length of the accuracy list

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range_fine, acc_fine, label='Training Accuracy (Fine-tuning)')
plt.plot(epochs_range_fine, val_acc_fine, label='Validation Accuracy (Fine-tuning)')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy (Fine-tuning)')

plt.subplot(1, 2, 2)
plt.plot(epochs_range_fine, loss_fine, label='Training Loss (Fine-tuning)')
plt.plot(epochs_range_fine, val_loss_fine, label='Validation Loss (Fine-tuning)')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss (Fine-tuning)')
plt.show()

loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

import os
import matplotlib.pyplot as plt

# Create the folder
os.makedirs("results", exist_ok=True)

# Create and save a sample plot (or your real results)
plt.plot([1, 2, 3], [0.9, 0.95, 0.97])
plt.title("Dummy Accuracy Plot")
plt.savefig("results/accuracy_plot.png")

# Save a simple text result
with open("results/eval.txt", "w") as f:
    f.write("Test Accuracy: 97.00%\n")

# Predict on test data
pred_probs = model.predict(test_generator)
pred_classes = np.argmax(pred_probs, axis=1)

# True labels
true_classes = test_generator.classes

# Class label names
class_labels = list(test_generator.class_indices.keys())

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Get predictions
pred_classes = np.argmax(pred_probs, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Print report
print(classification_report(true_classes, pred_classes, target_names=class_labels))

import matplotlib.pyplot as plt
import os
import random
from PIL import Image

def show_sample_images(directory, label, num=5):
    path = os.path.join(directory, label)
    images = random.sample(os.listdir(path), num)

    plt.figure(figsize=(15, 3))
    for i, img_name in enumerate(images):
        img_path = os.path.join(path, img_name)
        img = Image.open(img_path)
        plt.subplot(1, num, i+1)
        plt.imshow(img)
        plt.axis('off')
        plt.title(label)
    plt.suptitle(f'Sample Images from {directory}')
    plt.show()

# Example:
show_sample_images('/content/data/train', 'Angelina Jolie')
show_sample_images('/content/data/val', 'Angelina Jolie')
show_sample_images('/content/data/test', 'Angelina Jolie')

import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

# Step 1: Predict on test data
pred_probs = model.predict(test_generator)
pred_classes = np.argmax(pred_probs, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Step 2: Generate confusion matrix
cm = confusion_matrix(true_classes, pred_classes)

# Step 3: Plot it with seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix on Test Set')
plt.show()

# Optional: Classification report for more detail
print(classification_report(true_classes, pred_classes, target_names=class_labels))

import os
import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
from tensorflow.keras.models import load_model
from google.colab import files
import shutil

# Make sure this matches your test data generator
# Example: test_generator = test_datagen.flow_from_directory(...)

# Predict
y_true = test_generator.classes
y_prob = model.predict(test_generator)
y_pred = np.argmax(y_prob, axis=1)
class_labels = list(test_generator.class_indices.keys())

# Create results folder
os.makedirs("results", exist_ok=True)

# Save classification report (includes precision, recall, f1)
report = classification_report(y_true, y_pred, target_names=class_labels)
with open("results/classification_report.txt", "w") as f:
    f.write(report)

# Save as structured CSV
report_dict = classification_report(y_true, y_pred, target_names=class_labels, output_dict=True)
pd.DataFrame(report_dict).transpose().to_csv("results/precision_recall_f1.csv")

# Save confusion matrix
cm = confusion_matrix(y_true, y_pred)
pd.DataFrame(cm, index=class_labels, columns=class_labels).to_csv("results/confusion_matrix.csv")

# OPTIONAL: Save prediction sample
np.savetxt("results/y_true.txt", y_true, fmt="%d")
np.savetxt("results/y_pred.txt", y_pred, fmt="%d")

# Zip everything
shutil.make_archive("model_results", 'zip', "results")

# Trigger download
files.download("model_results.zip")

oss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import numpy as np

# Buat confusion matrix
cm = confusion_matrix(true_classes, pred_classes)
cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]  # normalize ke baris

# Bikin heatmap
plt.figure(figsize=(12, 10))
sns.heatmap(cm_norm, annot=True, fmt=".2f", cmap="Blues", xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Normalized Confusion Matrix Normalized")
plt.show()