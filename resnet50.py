# -*- coding: utf-8 -*-
"""Resnet50.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-dyQ3_OcMesl-Xwd6o4O22Fj-_D2Vtii
"""

!pip install kaggle

from google.colab import files
files.upload()

!mkdir -p ~/.kaggle
!cp kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json

!kaggle datasets download -d vishesh1412/celebrity-face-image-dataset

!unzip celebrity-face-image-dataset.zip -d ./celebrity_data

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import ResNet50
from tensorflow.keras.layers import Dense, Flatten, Dropout, GlobalAveragePooling2D
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import os
import shutil
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import cv2

dataset_path = './celebrity_data/Celebrity Faces Dataset'

# Get the list of celebrity names (which are the directory names)
celebrity_names = sorted(os.listdir(dataset_path))
num_classes = len(celebrity_names)
print(f"Found {num_classes} celebrities (classes).")
print("Celebrities:", celebrity_names)

# You can also count total images
total_images = 0
for celebrity in celebrity_names:
    celebrity_path = os.path.join(dataset_path, celebrity)
    if os.path.isdir(celebrity_path): # Ensure it's a directory
        num_images = len(os.listdir(celebrity_path))
        print(f"- {celebrity}: {num_images} images")
        total_images += num_images
print(f"\nTotal images in the dataset: {total_images}")

import os
import shutil
import random

# Customize this path to your dataset location
original_dataset_dir = './celebrity_data/Celebrity Faces Dataset'
base_dir = './data'

# Split ratios
train_split = 0.7
val_split = 0.15
test_split = 0.15

# Reset folders if they already exist
if os.path.exists(base_dir):
    shutil.rmtree(base_dir)

for split in ['train', 'val', 'test']:
    os.makedirs(os.path.join(base_dir, split), exist_ok=True)

# Loop through class folders
for class_name in os.listdir(original_dataset_dir):
    class_path = os.path.join(original_dataset_dir, class_name)
    if not os.path.isdir(class_path):
        continue

    # Create split folders for each class
    for split in ['train', 'val', 'test']:
        os.makedirs(os.path.join(base_dir, split, class_name), exist_ok=True)

    # Shuffle and split images
    images = os.listdir(class_path)
    random.shuffle(images)

    train_end = int(len(images) * train_split)
    val_end = train_end + int(len(images) * val_split)

    train_images = images[:train_end]
    val_images = images[train_end:val_end]
    test_images = images[val_end:]

    # Move files to respective directories
    for img in train_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'train', class_name, img))
    for img in val_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'val', class_name, img))
    for img in test_images:
        shutil.copy(os.path.join(class_path, img), os.path.join(base_dir, 'test', class_name, img))

print("âœ… Dataset split into train, val, and test!")

from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications.Resnet50 import preprocess_input
IMG_WIDTH, IMG_HEIGHT = 224, 224
BATCH_SIZE = 32

# Data generator for training (with augmentation)
train_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input,
    rotation_range=30,
    width_shift_range=0.25,
    height_shift_range=0.25,
    shear_range=0.25,
    zoom_range=0.25,
    horizontal_flip=True,
    brightness_range=[0.7, 1.3],
    channel_shift_range=20.0,
    fill_mode='nearest'
)

# Data generator for validation and testing (only preprocessing, no augmentation)
val_test_datagen = ImageDataGenerator(
    preprocessing_function=preprocess_input
)

# Paths to the newly created split directories
train_data_dir = './data/train'
val_data_dir = './data/val'
test_data_dir = './data/test'


train_generator = train_datagen.flow_from_directory(
    train_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=True,
    seed=42
)

validation_generator = val_test_datagen.flow_from_directory(
    val_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False,
    seed=42
)

test_generator = val_test_datagen.flow_from_directory(
    test_data_dir,
    target_size=(IMG_WIDTH, IMG_HEIGHT),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False,
    seed=42
)

# Verify class indices
print("\nTrain Generator Class Indices:", train_generator.class_indices)
print("Validation Generator Class Indices:", validation_generator.class_indices)
print("Test Generator Class Indices:", test_generator.class_indices)

# Store class labels for later use (ensure it's from train_generator as it's used for training)
class_labels = list(train_generator.class_indices.keys())
num_classes = len(class_labels) # Update num_classes based on actual classes found
print(f"\nNumber of classes detected by train_generator: {num_classes}")

import tensorflow as tf
from tensorflow.keras.applications import Resnet50

base_model = ResNet50(
    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3),
    include_top=False,
    weights='imagenet'
)

# Freeze the layers of the base model initially
base_model.trainable = False

# base_model.summary()

from tensorflow.keras.layers import resnet50, GlobalAveragePooling2D, Dropout
from tensorflow.keras.models import Model

# Get the output of the base model
x = base_model.output

# Add a global spatial average pooling layer
x = GlobalAveragePooling2D()(x)

# Add a fully-connected layer
x = Dense(1024, activation='relu')(x) # You can experiment with the number of neurons

# Add a dropout layer for regularization
x = Dropout(0.5)(x) # Dropout rate of 50%

# Add the final output layer with softmax activation for multi-class classification
# num_classes should be defined from the output of the new Cell 8
predictions = Dense(num_classes, activation='softmax')(x)

# Create the final model
model = Model(inputs=base_model.input, outputs=predictions)

# model.summary()

# For multi-class classification, categorical_crossentropy is common.
# Adam is a popular optimizer.
model.compile(optimizer=Adam(learning_rate=0.001), # You can tune the learning rate
              loss='categorical_crossentropy',
              metrics=['accuracy'])

early_stopping = EarlyStopping(
    monitor='val_loss',  # Metric to monitor (could also be 'val_accuracy')
    patience=10,         # Number of epochs with no improvement after which training will be stopped
                         # Increase if you think your model needs more time to converge,
                         # decrease if it overfits too quickly.
    verbose=1,           # To see messages when it triggers
    restore_best_weights=True # Restores model weights from the epoch with the best
                              # value of the monitored metric. This is VERY useful!
)

# ModelCheckpoint: Saves the model or weights at some interval.
# We'll save only the best model based on 'val_loss'.
model_checkpoint_path = 'best_face_recognition_model.keras' # Using .keras format
model_checkpoint = ModelCheckpoint(
    filepath=model_checkpoint_path,
    monitor='val_loss',    # Metric to monitor
    save_best_only=True,   # Only save the model if `val_loss` has improved
    verbose=1              # To see messages when the model is saved
)

EPOCHS = 50 # Start with a moderate number of epochs, e.g., 10-25
            # You can increase this later if the model is still improving.

history = model.fit(
    train_generator,
    epochs=EPOCHS,
    validation_data=validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

model.save('celebrity_face_recognition_model.h5') # Saves the model in HDF5 format
# Or for TensorFlow SavedModel format:
# model.save('celebrity_face_recognition_model_tf')

# Evaluate the model
val_loss, val_accuracy = model.evaluate(validation_generator)
print(f"\nValidation Loss: {val_loss:.4f}")
print(f"Validation Accuracy: {val_accuracy*100:.2f}%")

# Plot training & validation accuracy and loss
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']
loss = history.history['loss']
val_loss = history.history['val_loss']

epochs_range = range(len(acc)) # Use len(acc) to get the actual number of epochs run

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

# --- Optional: Fine-tuning ---
# Unfreeze some layers of the base model
base_model.trainable = True

# Fine-tune from this layer onwards
fine_tune_at = 100 # Example: Unfreeze layers from the 100th layer onwards
                   # For MobileNetV2, a good starting point might be after a certain block.
                   # You'll need to inspect base_model.summary() to choose this.

for layer in base_model.layers[:fine_tune_at]:
    layer.trainable = False

# Re-compile the model with a lower learning rate for fine-tuning
model.compile(optimizer=Adam(learning_rate=0.0001), # Lower learning rate
              loss='categorical_crossentropy',
              metrics=['accuracy'])

# model.summary() # Check which layers are trainable

# Continue training (fine-tuning)
FINE_TUNE_EPOCHS = 30 # Train for a few more epochs
TOTAL_EPOCHS = EPOCHS + FINE_TUNE_EPOCHS

history_fine_tune = model.fit(
    train_generator,
    epochs=TOTAL_EPOCHS,
    initial_epoch=history.epoch[-1] + 1, # Start from where the previous training stopped
    validation_data=validation_generator,
    callbacks=[early_stopping, model_checkpoint]
)

# Save the fine-tuned model
model.save('celebrity_face_recognition_model_fine_tuned.h5')

# Plot the fine-tuning results (append to previous history)
# acc += history_fine_tune.history['accuracy']
# val_acc += history_fine_tune.history['val_accuracy']
# loss += history_fine_tune.history['loss']
# val_loss += history_fine_tune.history['val_loss']

# epochs_range_fine_tune = range(TOTAL_EPOCHS)

#  plt.figure(figsize=(12, 4))
#  plt.subplot(1, 2, 1)
#  plt.plot(epochs_range_fine_tune, acc, label='Training Accuracy')
#  plt.plot(epochs_range_fine_tune, val_acc, label='Validation Accuracy')
#  plt.legend(loc='lower right')
#  plt.title('Training and Validation Accuracy (with Fine-Tuning)')

#  plt.subplot(1, 2, 2)
#  plt.plot(epochs_range_fine_tune, loss, label='Training Loss')
#  plt.plot(epochs_range_fine_tune, val_loss, label='Validation Loss')
#  plt.legend(loc='upper right')
#  plt.title('Training and Validation Loss (with Fine-Tuning)')
#  plt.show()

# --- Plot Fine-tuning Results ---
acc_fine = history_fine_tune.history['accuracy']
val_acc_fine = history_fine_tune.history['val_accuracy']
loss_fine = history_fine_tune.history['loss']
val_loss_fine = history_fine_tune.history['val_loss']

epochs_range_fine = range(len(acc_fine)) # Use the length of the accuracy list

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(epochs_range_fine, acc_fine, label='Training Accuracy (Fine-tuning)')
plt.plot(epochs_range_fine, val_acc_fine, label='Validation Accuracy (Fine-tuning)')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy (Fine-tuning)')

plt.subplot(1, 2, 2)
plt.plot(epochs_range_fine, loss_fine, label='Training Loss (Fine-tuning)')
plt.plot(epochs_range_fine, val_loss_fine, label='Validation Loss (Fine-tuning)')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss (Fine-tuning)')
plt.show()

loss, accuracy = model.evaluate(test_generator)
print(f"Test Loss: {loss:.4f}")
print(f"Test Accuracy: {accuracy:.4f}")

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix

# Get predictions
pred_probs = model.predict(test_generator)
pred_classes = np.argmax(pred_probs, axis=1)
true_classes = test_generator.classes
class_labels = list(test_generator.class_indices.keys())

# Print report
print(classification_report(true_classes, pred_classes, target_names=class_labels))